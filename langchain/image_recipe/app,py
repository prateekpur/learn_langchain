import os
import json
import requests
import re
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain_text_splitters import CharacterTextSplitter
from langchain.document_loaders import PyPDFLoader
import pandas as pd
from PyPDF2 import PdfReader
from dotenv import find_dotenv, load_dotenv
import openai
from langchain.chat_models import ChatOpenAI
from langchain.llms import OpenAI
from langchain.agents import Tool, initialize_agent, load_tools
from langchain.chains import LLMChain, LLMMathChain
from langchain.prompts import PromptTemplate
from langchain import LLMChain, PromptTemplate, Wikipedia
from langchain.memory import ConversationBufferMemory
from langchain.agents.react.base import DocstoreExplorer
from langchain.document_loaders import PyPDFLoader
from langchain.utilities import GoogleSerperAPIWrapper
from langchain_community.document_loaders import UnstructuredURLLoader
from langchain_community.vectorstores import FAISS
from langchain.chains.question_answering import load_qa_chain
# Use a pipeline as a high-level helper
from transformers import pipeline

pipe = pipeline("image-to-text", model="Salesforce/blip-image-captioning-base")

load_dotenv()

def image_to_text(url):
    HG_API_KEY = os.getenv("OPENAI_API_KEY")
    pipe = pipeline("image-to-text", model="Salesforce/blip-image-captioning-large", max_new_tokens=1000)
    text = pipe(url)[0]['generated_text']
    print(f"Text !@#!@#!@# {text}")
    return text

def main():
    caption = image_to_text(url = "/Users/prateekpuri/ai_agent/miscllaneous1978/coursera/learn_langchain/langchain/image_recipe/3food_1.jpeg")
    print()

if __name__ == "__main__":
    main()
